{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project Summary: \n",
    "\n",
    "In this project, I use data wrangling techniques, such as assessing the quality of the data for validity, accuracy, completeness, consistency and uniformity, to clean OpenStreetMap data. Then I convert the dataset from XML to CSV format, import the cleaned .csv files into database, conduct SQL queries to provide a statistical overview of the dataset. Finally, I give some additional suggestions for improving and analyzing the data.\n",
    "Map Area: Stokholm\n",
    "Split osm file into a smaller sample (SAMPLE_FILE). The original file (Stockholm) is 2GB. Challenges: activating python2 via source activate py2 to be able to run the following code(the code is written for py2). I stared with k=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET  # we can use cElementTree or lxml if too slow\n",
    "\n",
    "OSM_FILE = \"stockholm_sweden.osm\"  \n",
    "SAMPLE_FILE = \"sample.osm\"\n",
    "\n",
    "k = 10 # Parameter: take every k-th top level element\n",
    "\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\n",
    "\n",
    "    Reference:\n",
    "    http://stackoverflow.com/questions/3095434/inserting-newlines-in-xml-file-generated-via-xml-etree-elementtree-in-python\n",
    "    \"\"\"\n",
    "    context = iter(ET.iterparse(osm_file, events=('start', 'end')))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "\n",
    "with open(SAMPLE_FILE, 'wb') as output:\n",
    "    output.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n')\n",
    "    output.write('<osm>\\n  ')\n",
    "\n",
    "    # Write every kth top level element\n",
    "    for i, element in enumerate(get_element(OSM_FILE)):\n",
    "        if i % k == 0:\n",
    "            output.write(ET.tostring(element, encoding='utf-8'))\n",
    "\n",
    "    output.write('</osm>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse data-set and identify different tags, using iterative parsing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'member': 19825,\n",
      " 'nd': 745157,\n",
      " 'node': 610544,\n",
      " 'osm': 1,\n",
      " 'relation': 1012,\n",
      " 'tag': 216022,\n",
      " 'way': 69782}\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "import pprint\n",
    "from collections import defaultdict\n",
    "import collections\n",
    "\n",
    "def count_tags(filename):\n",
    "        all_tags=ET.iterparse(filename)\n",
    "        nodes= defaultdict(int)\n",
    "        for node in all_tags:\n",
    "            nodes[node[1].tag] +=1\n",
    "        return dict(nodes)           \n",
    "    \n",
    "def test():\n",
    "\n",
    "    tags = count_tags(SAMPLE_FILE)\n",
    "    pprint.pprint(tags)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unique users contributed to the map in this particular area:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1883\n"
     ]
    }
   ],
   "source": [
    "def process_map(filename):\n",
    "    users = set()\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        if \"uid\" in element.attrib:\n",
    "            users.add(element.get('uid'))\n",
    "\n",
    "    return users\n",
    "\n",
    "def test():\n",
    "\n",
    "    users = process_map(SAMPLE_FILE)\n",
    "    pprint.pprint(len(users))\n",
    "#    assert len(users) == 6\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# auditing \n",
    "One of the usual problems in openstreetmap dataset is from the street name abbreviation. However, I have not found any problems by only looking at the osm file. Here I will try to find something via my code.\n",
    "1-Building the regular expression to match the last element in the string, where usually the street type is based. \n",
    "2-Then based on the street abbreviation, create a mapping that need to be cleaned.\n",
    "\n",
    "I tried all sort of changes in my code, however the resut looks pretty good(Swedes are really good at documentation afterall ;). in addition, Swedish wording is differnet in many ways. Namely for a street-name+street_type it usually only one world 'namestreet'; for example 'axfordstreet' as only one word. therefore, if the code recognises the last word which is not detected as an expected will return it as a name to be updated. to avoid the confusion and to avoid printing 2G worth of streettypes, I only dupdate street types with lower case in their first letter with most common swidish street types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Farnaz/anaconda/envs/py2/lib/python2.7/site-packages/ipykernel/__main__.py:31: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<type 'set'>, {'torg': set(['Valla torg'])})\n",
      "defaultdict(<type 'set'>, {u'gatan': set([u'Gr\\xf6na gatan']), 'torg': set(['Valla torg'])})\n",
      "defaultdict(<type 'set'>, {u'gatan': set([u'Gr\\xf6na gatan']), 'torg': set(['Valla torg'])})\n",
      "defaultdict(<type 'set'>, {u'gatan': set([u'Gr\\xf6na gatan']), 'torg': set(['Valla torg'])})\n",
      "defaultdict(<type 'set'>, {u'gatan': set([u'Gr\\xf6na gatan']), 'torg': set(['Valla torg'])})\n",
      "defaultdict(<type 'set'>, {u'gatan': set([u'Gr\\xf6na gatan']), 'torg': set(['Valla torg'])})\n",
      "defaultdict(<type 'set'>, {u'gatan': set([u'Gr\\xf6na gatan']), 'torg': set(['Valla torg', 'Kista torg'])})\n",
      "defaultdict(<type 'set'>, {u'gatan': set([u'Gr\\xf6na gatan']), 'Gatan': set(['Tysta Gatan']), 'torg': set(['Valla torg', 'Kista torg'])})\n",
      "defaultdict(<type 'set'>, {u'gatan': set([u'Gr\\xf6na gatan']), 'Gatan': set(['Tysta Gatan']), 'torg': set(['Valla torg', 'Kista torg'])})\n",
      "defaultdict(<type 'set'>, {u'gatan': set([u'Gr\\xf6na gatan']), 'Gatan': set(['Tysta Gatan']), 'torg': set(['Valla torg', 'Kista torg']), 'Boulevard': set(['Gustav III:s Boulevard'])})\n",
      "defaultdict(<type 'set'>, {u'gatan': set([u'Gr\\xf6na gatan']), 'Gatan': set(['Tysta Gatan']), 'torg': set(['Valla torg', 'Kista torg']), 'Boulevard': set(['Gustav III:s Boulevard'])})\n",
      "defaultdict(<type 'set'>, {u'gatan': set([u'Gr\\xf6na gatan']), 'Gatan': set(['Tysta Gatan']), 'torg': set(['Valla torg', 'Kista torg']), 'Boulevard': set(['Gustav III:s Boulevard'])})\n",
      "defaultdict(<type 'set'>, {u'gatan': set([u'Gr\\xf6na gatan']), 'Gatan': set(['Tysta Gatan']), 'torg': set(['Valla torg', 'Kista torg']), 'Boulevard': set(['Gustav III:s Boulevard'])})\n",
      "defaultdict(<type 'set'>, {u'gatan': set([u'Gr\\xf6na gatan']), 'Gatan': set(['Tysta Gatan']), 'torg': set(['Valla torg', 'Kista torg']), 'Boulevard': set(['Gustav III:s Boulevard'])})\n",
      "defaultdict(<type 'set'>, {u'gatan': set([u'Gr\\xf6na gatan']), 'Gatan': set(['Tysta Gatan']), 'torg': set(['Gustaf de Lavals torg', 'Valla torg', 'Kista torg']), 'Boulevard': set(['Gustav III:s Boulevard'])})\n",
      "defaultdict(<type 'set'>, {u'gatan': set([u'Gr\\xf6na gatan']), 'Gatan': set([u'L\\xe5nga Gatan', 'Tysta Gatan']), 'torg': set(['Gustaf de Lavals torg', 'Valla torg', 'Kista torg']), 'Boulevard': set(['Gustav III:s Boulevard'])})\n",
      "defaultdict(<type 'set'>, {u'gatan': set([u'Gr\\xf6na gatan']), 'Gatan': set(['Breda Gatan', u'L\\xe5nga Gatan', 'Tysta Gatan']), 'torg': set(['Gustaf de Lavals torg', 'Valla torg', 'Kista torg']), 'Boulevard': set(['Gustav III:s Boulevard'])})\n",
      "defaultdict(<type 'set'>, {u'gatan': set([u'Gr\\xf6na gatan']), 'Gatan': set(['Breda Gatan', u'L\\xe5nga Gatan', 'Tysta Gatan']), 'torg': set(['Gustaf de Lavals torg', 'Valla torg', 'Kista torg']), 'Boulevard': set(['Gustav III:s Boulevard'])})\n",
      "defaultdict(<type 'set'>, {u'gatan': set([u'Gr\\xf6na gatan', u'\\xd6stra \\xc5gatan']), 'Gatan': set(['Breda Gatan', u'L\\xe5nga Gatan', 'Tysta Gatan']), 'torg': set(['Gustaf de Lavals torg', 'Valla torg', 'Kista torg']), 'Boulevard': set(['Gustav III:s Boulevard'])})\n",
      "defaultdict(<type 'set'>, {u'gatan': set([u'Gr\\xf6na gatan', u'\\xd6stra \\xc5gatan']), 'Gatan': set(['Breda Gatan', u'L\\xe5nga Gatan', 'Tysta Gatan']), 'torg': set(['Gustaf de Lavals torg', 'Valla torg', 'Kista torg']), 'Boulevard': set(['Gustav III:s Boulevard'])})\n",
      "defaultdict(<type 'set'>, {u'gatan': set([u'Gr\\xf6na gatan', 'Finska gatan', u'\\xd6stra \\xc5gatan']), 'Gatan': set(['Breda Gatan', u'L\\xe5nga Gatan', 'Tysta Gatan']), 'torg': set(['Gustaf de Lavals torg', 'Valla torg', 'Kista torg']), 'Boulevard': set(['Gustav III:s Boulevard'])})\n",
      "defaultdict(<type 'set'>, {u'gatan': set([u'Gr\\xf6na gatan', 'Finska gatan', u'\\xd6stra \\xc5gatan']), 'Gatan': set(['Breda Gatan', u'L\\xe5nga Gatan', 'Tysta Gatan']), 'torg': set(['Gustaf de Lavals torg', 'Valla torg', 'Kista torg']), 'Boulevard': set(['Gustav III:s Boulevard'])})\n",
      "defaultdict(<type 'set'>, {u'gatan': set([u'Gr\\xf6na gatan', 'Finska gatan', u'\\xd6stra \\xc5gatan']), 'Gatan': set(['Breda Gatan', u'L\\xe5nga Gatan', 'Tysta Gatan']), 'torg': set(['Gustaf de Lavals torg', 'Valla torg', 'Kista torg']), 'Boulevard': set(['Gustav III:s Boulevard'])})\n",
      "defaultdict(<type 'set'>, {u'gatan': set([u'Gr\\xf6na gatan', 'Finska gatan', u'\\xd6stra \\xc5gatan']), 'Gatan': set(['Breda Gatan', u'L\\xe5nga Gatan', 'Tysta Gatan']), 'torg': set(['Gustaf de Lavals torg', 'Valla torg', 'Kista torg']), 'Boulevard': set(['Gustav III:s Boulevard'])})\n",
      "defaultdict(<type 'set'>, {u'gatan': set([u'Gr\\xf6na gatan', 'Finska gatan', u'\\xd6stra \\xc5gatan', u'V\\xe4stra \\xc5gatan']), 'Gatan': set(['Breda Gatan', u'L\\xe5nga Gatan', 'Tysta Gatan']), 'torg': set(['Gustaf de Lavals torg', 'Valla torg', 'Kista torg']), 'Boulevard': set(['Gustav III:s Boulevard'])})\n",
      "defaultdict(<type 'set'>, {u'gatan': set(['Lugna gatan', u'Gr\\xf6na gatan', 'Finska gatan', u'\\xd6stra \\xc5gatan', u'V\\xe4stra \\xc5gatan']), 'Gatan': set(['Breda Gatan', u'L\\xe5nga Gatan', 'Tysta Gatan']), 'torg': set(['Gustaf de Lavals torg', 'Valla torg', 'Kista torg']), 'Boulevard': set(['Gustav III:s Boulevard'])})\n",
      "defaultdict(<type 'set'>, {u'gatan': set(['Lugna gatan', u'Gr\\xf6na gatan', 'Finska gatan', u'\\xd6stra \\xc5gatan', u'V\\xe4stra \\xc5gatan']), 'Gatan': set(['Breda Gatan', u'L\\xe5nga Gatan', 'Tysta Gatan']), 'torg': set(['Gustaf de Lavals torg', 'Valla torg', 'Kista torg']), 'Boulevard': set(['Gustav III:s Boulevard'])})\n",
      "defaultdict(<type 'set'>, {u'gatan': set(['Lugna gatan', u'Gr\\xf6na gatan', 'Finska gatan', u'\\xd6stra \\xc5gatan', u'V\\xe4stra \\xc5gatan']), 'Gatan': set(['Breda Gatan', u'L\\xe5nga Gatan', 'Tysta Gatan']), 'torg': set(['Gustaf de Lavals torg', 'Valla torg', 'Kista torg']), 'Boulevard': set(['Gustav III:s Boulevard'])})\n",
      "defaultdict(<type 'set'>, {u'gatan': set(['Lugna gatan', u'Gr\\xf6na gatan', 'Finska gatan', u'\\xd6stra \\xc5gatan', u'V\\xe4stra \\xc5gatan']), 'Gatan': set(['Breda Gatan', u'L\\xe5nga Gatan', 'Tysta Gatan']), 'torg': set(['Gustaf de Lavals torg', 'Valla torg', 'Kista torg']), 'Boulevard': set(['Gustav III:s Boulevard'])})\n",
      "defaultdict(<type 'set'>, {u'gatan': set(['Lugna gatan', u'Gr\\xf6na gatan', 'Finska gatan', u'\\xd6stra \\xc5gatan', u'V\\xe4stra \\xc5gatan']), 'Gatan': set(['Breda Gatan', u'L\\xe5nga Gatan', 'Tysta Gatan']), 'torg': set(['Gustaf de Lavals torg', 'Valla torg', 'Kista torg']), 'Boulevard': set(['Gustav III:s Boulevard'])})\n",
      "defaultdict(<type 'set'>, {u'gatan': set(['Lugna gatan', u'Gr\\xf6na gatan', 'Finska gatan', u'\\xd6stra \\xc5gatan', u'V\\xe4stra \\xc5gatan']), 'Gatan': set(['Breda Gatan', u'L\\xe5nga Gatan', 'Tysta Gatan']), 'torg': set(['Gustaf de Lavals torg', 'Valla torg', 'Kista torg']), 'Boulevard': set(['Gustav III:s Boulevard'])})\n",
      "defaultdict(<type 'set'>, {u'gatan': set(['Lugna gatan', u'Gr\\xf6na gatan', 'Finska gatan', u'\\xd6stra \\xc5gatan', u'V\\xe4stra \\xc5gatan']), 'Gatan': set(['Breda Gatan', u'L\\xe5nga Gatan', 'Tysta Gatan']), 'torg': set(['Gustaf de Lavals torg', 'Valla torg', 'Kista torg']), 'Boulevard': set(['Gustav III:s Boulevard'])})\n",
      "defaultdict(<type 'set'>, {u'gatan': set(['Lugna gatan', u'Gr\\xf6na gatan', 'Finska gatan', u'\\xd6stra \\xc5gatan', u'V\\xe4stra \\xc5gatan']), 'Gatan': set(['Breda Gatan', u'L\\xe5nga Gatan', 'Tysta Gatan']), 'torg': set(['Gustaf de Lavals torg', 'Valla torg', 'Kista torg']), 'Boulevard': set(['Gustav III:s Boulevard'])})\n",
      "defaultdict(<type 'set'>, {u'gatan': set(['Lugna gatan', u'Gr\\xf6na gatan', 'Finska gatan', u'\\xd6stra \\xc5gatan', u'V\\xe4stra \\xc5gatan']), 'Gatan': set(['Breda Gatan', u'L\\xe5nga Gatan', 'Tysta Gatan']), 'torg': set(['Gustaf de Lavals torg', 'Valla torg', 'Kista torg']), 'Boulevard': set(['Gustav III:s Boulevard'])})\n",
      "defaultdict(<type 'set'>, {u'gatan': set(['Lugna gatan', u'Gr\\xf6na gatan', 'Finska gatan', u'\\xd6stra \\xc5gatan', u'V\\xe4stra \\xc5gatan']), 'Gatan': set(['Breda Gatan', u'L\\xe5nga Gatan', 'Tysta Gatan']), 'torg': set(['Gustaf de Lavals torg', 'Valla torg', 'Kista torg']), 'Boulevard': set(['Gustav III:s Boulevard'])})\n",
      "defaultdict(<type 'set'>, {u'gatan': set(['Lugna gatan', u'Gr\\xf6na gatan', 'Finska gatan', u'\\xd6stra \\xc5gatan', u'V\\xe4stra \\xc5gatan']), 'Gatan': set(['Breda Gatan', u'L\\xe5nga Gatan', 'Tysta Gatan']), 'torg': set(['Gustaf de Lavals torg', 'Valla torg', 'Kista torg']), 'Boulevard': set(['Gustav III:s Boulevard'])})\n",
      "defaultdict(<type 'set'>, {u'gatan': set(['Lugna gatan', u'Gr\\xf6na gatan', 'Finska gatan', u'\\xd6stra \\xc5gatan', u'V\\xe4stra \\xc5gatan']), 'Gatan': set(['Breda Gatan', u'L\\xe5nga Gatan', 'Tysta Gatan']), 'torg': set(['Gustaf de Lavals torg', 'Valla torg', 'Kista torg']), 'Boulevard': set(['Gustav III:s Boulevard'])})\n",
      "defaultdict(<type 'set'>, {u'gatan': set(['Lugna gatan', u'Gr\\xf6na gatan', 'Finska gatan', u'\\xd6stra \\xc5gatan', u'V\\xe4stra \\xc5gatan']), 'Gatan': set(['Breda Gatan', u'L\\xe5nga Gatan', 'Tysta Gatan']), 'torg': set(['Gustaf de Lavals torg', 'Valla torg', 'Kista torg']), 'Boulevard': set(['Gustav III:s Boulevard'])})\n",
      "defaultdict(<type 'set'>, {u'gatan': set(['Lugna gatan', u'Gr\\xf6na gatan', 'Finska gatan', u'\\xd6stra \\xc5gatan', u'V\\xe4stra \\xc5gatan']), 'Gatan': set(['Breda Gatan', u'L\\xe5nga Gatan', 'Tysta Gatan']), 'torg': set(['Gustaf de Lavals torg', 'Valla torg', 'Kista torg']), 'Boulevard': set(['Gustav III:s Boulevard'])})\n",
      "defaultdict(<type 'set'>, {u'gatan': set(['Lugna gatan', u'Gr\\xf6na gatan', 'Finska gatan', u'\\xd6stra \\xc5gatan', u'V\\xe4stra \\xc5gatan']), 'Gatan': set(['Breda Gatan', u'L\\xe5nga Gatan', 'Tysta Gatan']), 'torg': set(['Gustaf de Lavals torg', 'Valla torg', 'Kista torg']), 'Boulevard': set(['Gustav III:s Boulevard'])})\n",
      "defaultdict(<type 'set'>, {u'gatan': set(['Lugna gatan', u'Gr\\xf6na gatan', 'Finska gatan', u'\\xd6stra \\xc5gatan', u'V\\xe4stra \\xc5gatan']), 'Gatan': set(['Breda Gatan', u'L\\xe5nga Gatan', 'Tysta Gatan']), 'torg': set(['Gustaf de Lavals torg', 'Valla torg', 'Kista torg']), 'Boulevard': set(['Gustav III:s Boulevard'])})\n",
      "defaultdict(<type 'set'>, {u'gatan': set(['Lugna gatan', u'Gr\\xf6na gatan', 'Finska gatan', u'\\xd6stra \\xc5gatan', u'V\\xe4stra \\xc5gatan']), 'Gatan': set(['Breda Gatan', u'L\\xe5nga Gatan', 'Tysta Gatan']), 'torg': set(['Gustaf de Lavals torg', 'Valla torg', 'Kista torg']), 'Boulevard': set(['Gustav III:s Boulevard'])})\n",
      "defaultdict(<type 'set'>, {u'gatan': set(['Lugna gatan', u'Gr\\xf6na gatan', 'Finska gatan', u'\\xd6stra \\xc5gatan', u'V\\xe4stra \\xc5gatan']), 'Gatan': set(['Breda Gatan', u'L\\xe5nga Gatan', 'Tysta Gatan']), 'torg': set(['Gustaf de Lavals torg', 'Valla torg', 'Kista torg']), 'Boulevard': set(['Gustav III:s Boulevard'])})\n",
      "defaultdict(<type 'set'>, {u'gatan': set(['Lugna gatan', u'Gr\\xf6na gatan', 'Finska gatan', u'\\xd6stra \\xc5gatan', u'V\\xe4stra \\xc5gatan']), 'Gatan': set(['Breda Gatan', u'L\\xe5nga Gatan', 'Tysta Gatan']), 'torg': set(['Gustaf de Lavals torg', 'Valla torg', 'Kista torg']), 'Boulevard': set(['Gustav III:s Boulevard'])})\n",
      "defaultdict(<type 'set'>, {u'gatan': set(['Lugna gatan', u'Gr\\xf6na gatan', 'Finska gatan', u'\\xd6stra \\xc5gatan', u'V\\xe4stra \\xc5gatan']), 'Gatan': set(['Breda Gatan', u'L\\xe5nga Gatan', 'Tysta Gatan']), 'torg': set(['Gustaf de Lavals torg', 'Valla torg', 'Kista torg']), 'Boulevard': set(['Gustav III:s Boulevard'])})\n",
      "defaultdict(<type 'set'>, {u'gatan': set(['Lugna gatan', u'Gr\\xf6na gatan', 'Finska gatan', u'\\xd6stra \\xc5gatan', u'V\\xe4stra \\xc5gatan']), 'Gatan': set(['Breda Gatan', u'L\\xe5nga Gatan', 'Tysta Gatan']), 'torg': set(['Gustaf de Lavals torg', 'Valla torg', 'Kista torg']), 'Boulevard': set(['Gustav III:s Boulevard'])})\n",
      "defaultdict(<type 'set'>, {u'gatan': set(['Lugna gatan', u'Gr\\xf6na gatan', 'Finska gatan', u'\\xd6stra \\xc5gatan', u'V\\xe4stra \\xc5gatan']), 'Gatan': set(['Breda Gatan', u'L\\xe5nga Gatan', 'Tysta Gatan']), 'torg': set(['Gustaf de Lavals torg', 'Valla torg', 'Kista torg']), 'Boulevard': set(['Gustav III:s Boulevard'])})\n",
      "defaultdict(<type 'set'>, {u'gatan': set(['Lugna gatan', u'Gr\\xf6na gatan', 'Finska gatan', u'\\xd6stra \\xc5gatan', u'V\\xe4stra \\xc5gatan']), 'Gatan': set(['Breda Gatan', u'L\\xe5nga Gatan', 'Tysta Gatan']), 'torg': set(['Gustaf de Lavals torg', 'Valla torg', 'Kista torg']), 'Boulevard': set(['Gustav III:s Boulevard'])})\n",
      "defaultdict(<type 'set'>, {u'gatan': set(['Lugna gatan', u'Gr\\xf6na gatan', 'Finska gatan', u'\\xd6stra \\xc5gatan', u'V\\xe4stra \\xc5gatan']), 'Gatan': set(['Breda Gatan', u'L\\xe5nga Gatan', 'Tysta Gatan']), 'torg': set(['Gustaf de Lavals torg', 'Valla torg', 'Kista torg']), 'Boulevard': set(['Gustav III:s Boulevard'])})\n",
      "defaultdict(<type 'set'>, {u'gatan': set(['Lugna gatan', u'Gr\\xf6na gatan', 'Finska gatan', u'\\xd6stra \\xc5gatan', u'V\\xe4stra \\xc5gatan']), 'Gatan': set(['Breda Gatan', u'L\\xe5nga Gatan', 'Tysta Gatan']), 'torg': set(['Gustaf de Lavals torg', 'Valla torg', 'Kista torg']), 'Boulevard': set(['Gustav III:s Boulevard'])})\n",
      "defaultdict(<type 'set'>, {u'gatan': set(['Lugna gatan', u'Gr\\xf6na gatan', 'Finska gatan', u'\\xd6stra \\xc5gatan', u'V\\xe4stra \\xc5gatan']), 'Gatan': set(['Breda Gatan', u'L\\xe5nga Gatan', 'Tysta Gatan']), 'torg': set(['Gustaf de Lavals torg', 'Valla torg', 'Kista torg']), 'Boulevard': set(['Gustav III:s Boulevard'])})\n",
      "defaultdict(<type 'set'>, {u'gatan': set(['Lugna gatan', u'Gr\\xf6na gatan', 'Finska gatan', u'\\xd6stra \\xc5gatan', u'V\\xe4stra \\xc5gatan']), 'Gatan': set(['Breda Gatan', u'L\\xe5nga Gatan', 'Tysta Gatan']), 'torg': set(['Gustaf de Lavals torg', 'Valla torg', 'Kista torg']), 'Boulevard': set(['Gustav III:s Boulevard'])})\n",
      "defaultdict(<type 'set'>, {u'gatan': set(['Lugna gatan', u'Gr\\xf6na gatan', 'Finska gatan', u'\\xd6stra \\xc5gatan', u'V\\xe4stra \\xc5gatan']), 'Gatan': set(['Breda Gatan', u'L\\xe5nga Gatan', 'Tysta Gatan']), 'torg': set(['Gustaf de Lavals torg', 'Valla torg', 'Kista torg']), 'Boulevard': set(['Gustav III:s Boulevard'])})\n",
      "defaultdict(<type 'set'>, {u'gatan': set(['Lugna gatan', u'Gr\\xf6na gatan', 'Finska gatan', u'\\xd6stra \\xc5gatan', u'V\\xe4stra \\xc5gatan']), 'Gatan': set(['Breda Gatan', u'L\\xe5nga Gatan', 'Tysta Gatan']), 'torg': set(['Gustaf de Lavals torg', 'Valla torg', 'Kista torg']), 'Boulevard': set(['Gustav III:s Boulevard'])})\n",
      "defaultdict(<type 'set'>, {u'gatan': set(['Lugna gatan', u'Gr\\xf6na gatan', 'Finska gatan', u'\\xd6stra \\xc5gatan', u'V\\xe4stra \\xc5gatan']), 'Gatan': set(['Breda Gatan', u'L\\xe5nga Gatan', 'Tysta Gatan']), 'torg': set(['Gustaf de Lavals torg', 'Valla torg', 'Kista torg']), 'Boulevard': set(['Gustav III:s Boulevard'])})\n",
      "defaultdict(<type 'set'>, {u'gatan': set(['Lugna gatan', u'Gr\\xf6na gatan', 'Finska gatan', u'\\xd6stra \\xc5gatan', u'V\\xe4stra \\xc5gatan']), 'Gatan': set(['Breda Gatan', u'L\\xe5nga Gatan', 'Tysta Gatan']), 'torg': set(['Gustaf de Lavals torg', 'Valla torg', 'Kista torg']), 'Boulevard': set(['Gustav III:s Boulevard'])})\n",
      "defaultdict(<type 'set'>, {u'gatan': set(['Lugna gatan', u'Gr\\xf6na gatan', 'Finska gatan', u'\\xd6stra \\xc5gatan', u'V\\xe4stra \\xc5gatan']), 'Gatan': set(['Breda Gatan', u'L\\xe5nga Gatan', 'Tysta Gatan']), 'torg': set(['Gustaf de Lavals torg', 'Valla torg', 'Kista torg']), 'Boulevard': set(['Gustav III:s Boulevard'])})\n",
      "defaultdict(<type 'set'>, {u'gatan': set(['Lugna gatan', u'Gr\\xf6na gatan', 'Finska gatan', u'\\xd6stra \\xc5gatan', u'V\\xe4stra \\xc5gatan']), 'Gatan': set(['Breda Gatan', u'L\\xe5nga Gatan', 'Tysta Gatan']), 'torg': set(['Gustaf de Lavals torg', 'Valla torg', 'Kista torg']), 'Boulevard': set(['Gustav III:s Boulevard'])})\n",
      "defaultdict(<type 'set'>, {u'gatan': set(['Lugna gatan', u'Gr\\xf6na gatan', 'Finska gatan', u'\\xd6stra \\xc5gatan', u'V\\xe4stra \\xc5gatan']), 'Gatan': set(['Breda Gatan', u'L\\xe5nga Gatan', 'Tysta Gatan']), 'torg': set(['Gustaf de Lavals torg', 'Valla torg', 'Kista torg']), 'Boulevard': set(['Gustav III:s Boulevard'])})\n",
      "defaultdict(<type 'set'>, {u'gatan': set(['Lugna gatan', u'Gr\\xf6na gatan', 'Finska gatan', u'\\xd6stra \\xc5gatan', u'V\\xe4stra \\xc5gatan']), 'Gatan': set(['Breda Gatan', u'L\\xe5nga Gatan', 'Tysta Gatan']), 'torg': set(['Gustaf de Lavals torg', 'Valla torg', 'Kista torg']), 'Boulevard': set(['Gustav III:s Boulevard'])})\n",
      "defaultdict(<type 'set'>, {u'gatan': set(['Lugna gatan', u'Gr\\xf6na gatan', 'Finska gatan', u'\\xd6stra \\xc5gatan', u'V\\xe4stra \\xc5gatan']), 'Gatan': set(['Breda Gatan', u'L\\xe5nga Gatan', 'Tysta Gatan']), 'torg': set(['Gustaf de Lavals torg', 'Valla torg', 'Kista torg']), 'Boulevard': set(['Gustav III:s Boulevard'])})\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import xml.etree.cElementTree as ET\n",
    "import pprint\n",
    "from collections import defaultdict\n",
    "import collections\n",
    "\n",
    "street_types = collections.defaultdict(set)\n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "\n",
    "expected = [ \"Väg\", \"Gatan\", \"Alle\",\"Allé\", \"väg\",\"torg\",\"gatan\",\"alle\", \"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\",\n",
    "            \"Trail\", \"Parkway\", \"Commons\", \"Cove\", \"Alley\", \"Park\", \"Way\", \"Walk\" \"Circle\", \"Highway\",\n",
    "            \"Plaza\", \"Path\", \"Center\", \"Mission\", \"Kyrka\", \"kyrka\"]\n",
    "\n",
    "mapping = { \"väg\": \"Väg\" ,\n",
    "           \"torg\": \"Torg\",\n",
    "\n",
    "            \"gata\":\"Gatan\",\n",
    "            \"gatan\": \"Gatan\" ,\n",
    "            \"allé\" :\"Alle\",\n",
    "           \"boulevard\":\"Boulevard\",\n",
    "           \n",
    "\n",
    "            }\n",
    "\n",
    "def audit_street_type(street_types, street_name):\n",
    "#    print street_name\n",
    "    m = street_type_re.search(street_name) #finds the pattern of last words\n",
    "    if m:\n",
    "        street_type = m.group() #returns the last word\n",
    "\n",
    "        if street_type in expected:  ## here is my own interpretation of expected (for english speaking countries i would use #\"if street_type in expected: )#\n",
    "\n",
    "            street_types[street_type].add(street_name)\n",
    "            print street_types\n",
    "\n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "\n",
    "def audit(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "   \n",
    "    for event, elem in ET.iterparse(osmfile, events=(\"start\",)):\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "    osm_file.close()\n",
    "    return street_types\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    audit(SAMPLE_FILE)\n",
    "    pprint.pprint(audit(SAMPLE_FILE) )\n",
    "\n",
    "#    for name, street in street_types.items():\n",
    "\n",
    "#        print(\"/nSet:\", name, \"Entries:\"),\n",
    "#        for item in street:\n",
    "\n",
    "#            print (item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lugna gatan => Lugna Gatan\n",
      "Gröna gatan => Gröna Gatan\n",
      "Finska gatan => Finska Gatan\n",
      "Östra Ågatan => Östra ÅGatan\n",
      "Västra Ågatan => Västra ÅGatan\n",
      "Breda Gatan => Breda Gatan\n",
      "Långa Gatan => Långa Gatan\n",
      "Tysta Gatan => Tysta Gatan\n",
      "Gustaf de Lavals torg => Gustaf de Lavals Torg\n",
      "Valla torg => Valla Torg\n",
      "Kista torg => Kista Torg\n",
      "Gustav III:s Boulevard => Gustav III:s Boulevard\n"
     ]
    }
   ],
   "source": [
    "def update_name(name, mapping, regex):\n",
    "    m = regex.search(name)\n",
    "    if m:\n",
    "        st_type = m.group()\n",
    "        if st_type in mapping:\n",
    "            name = re.sub(regex, mapping[st_type], name)\n",
    "    return name\n",
    "for street_type, ways in street_types.iteritems():\n",
    "    for name in ways:\n",
    "        better_name = update_name(name, mapping, street_type_re)\n",
    "        print name, \"=>\", better_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking ‘k’ value for each tag. creating a dictionary of the different tags. Regular expressions: lower is for valid only-lowercase-letter tags. lower_colon is for other valid tags with a colon in the value. problemchars is for tags with problematic characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "\n",
    "def key_type(element, keys):\n",
    "    if element.tag == \"tag\":\n",
    "        if re.match(lower, element.attrib['k']):\n",
    "            keys[\"lower\"] += 1\n",
    "        elif re.match(lower_colon, element.attrib['k']):\n",
    "            keys[\"lower_colon\"] += 1\n",
    "        elif re.search(problemchars, element.attrib['k']):\n",
    "            keys[\"problemchars\"] += 1\n",
    "        else:\n",
    "            keys['other'] += 1\n",
    "    return keys\n",
    "\n",
    "\n",
    "def process_map(filename):\n",
    "    keys = {\"lower\": 0, \"lower_colon\": 0, \"problemchars\": 0, \"other\": 0}\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        keys = key_type(element, keys)\n",
    "\n",
    "    return keys\n",
    "\n",
    "sf_all_keys = process_map(SAMPLE_FILE)\n",
    "print sf_all_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auditing postal codes. The first two digit of postal codes in sweden is 72."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "def audit_zipcode(invalid_zipcodes, zipcode):\n",
    "    twoDigits = zipcode[0:2]\n",
    "    \n",
    "    if twoDigits != 72 or not twoDigits.isdigit():\n",
    "        invalid_zipcodes[twoDigits].add(zipcode)\n",
    "        \n",
    "def is_zipcode(elem):\n",
    "    return (elem.attrib['k'] == \"addr:postcode\")\n",
    "\n",
    "def audit_zip(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    invalid_zipcodes = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_zipcode(tag):\n",
    "                    audit_zipcode(invalid_zipcodes,tag.attrib['v'])\n",
    "\n",
    "    return invalid_zipcodes\n",
    "\n",
    "sf_zipcode = audit_zip(SAMPLE_FILE)\n",
    "pprint.pprint(dict(sf_zipcode))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problems Encountered: Inconsistent postal codes! Although I indicated invalid zipcode in a broad set, many of the above zipcodes are valid and have no promlebs. In Stockholm area zip codes all begin with “72” or “41”, however some of zip codes were outside this region.\n",
    "In the following code, I modify the function to clean zip code, change xxx xx-xxxx format into 5 digits format, to remove the blank in the middle and create a consistant zipcode. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def update_zip(zipcode):\n",
    "    zipcode= zipcode.replace(\" \",\"\")\n",
    "    zipChar = re.findall('[a-zA-Z]*', zipcode)\n",
    "    if zipChar:\n",
    "        zipChar = zipChar[0]\n",
    "    zipChar.strip()\n",
    "    if zipChar == \"u\":\n",
    "        updateZip = re.findall(r'\\d+', zipcode)\n",
    "        if updateZip:\n",
    "            return ((re.findall(r'\\d+', zipcode))[0])\n",
    "    else:\n",
    "            \n",
    "        d=((re.findall(r'\\d+', zipcode))[0])\n",
    "        return d\n",
    "        \n",
    "\n",
    "\n",
    "for street_type, ways in sf_zipcode.iteritems():\n",
    "    for name in ways:\n",
    "        better_name = update_zip(name)\n",
    "        print name, \"=>\", better_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After auditing is completed the next step is to prepare the data to be inserted into a SQL database.\n",
    "To do so I did parse the elements in the OSM XML file, transforming them from document format to\n",
    "tabular format, thus making it possible to write to .csv files.  These csv files can then easily be\n",
    "imported to a SQL database as tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import codecs\n",
    "import re\n",
    "import xml.etree.cElementTree as ET\n",
    "\n",
    "import cerberus\n",
    "\n",
    "import schema\n",
    "\n",
    "OSM_PATH = \"example.osm\"\n",
    "\n",
    "NODES_PATH = \"nodes.csv\"\n",
    "NODE_TAGS_PATH = \"nodes_tags.csv\"\n",
    "WAYS_PATH = \"ways.csv\"\n",
    "WAY_NODES_PATH = \"ways_nodes.csv\"\n",
    "WAY_TAGS_PATH = \"ways_tags.csv\"\n",
    "\n",
    "LOWER_COLON = re.compile(r'^([a-z]|_)+:([a-z]|_)+')\n",
    "                       # r'^([a-z]|_)*:([a-z]|_)*$'\n",
    "PROBLEMCHARS = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "SCHEMA = schema.schema\n",
    "\n",
    "# Make sure the fields order in the csvs matches the column order in the sql table schema\n",
    "NODE_FIELDS = ['id', 'lat', 'lon', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "NODE_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_FIELDS = ['id', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "WAY_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_NODES_FIELDS = ['id', 'node_id', 'position']\n",
    "\n",
    "\n",
    "def load_new_tag(element, secondary, default_tag_type):\n",
    "    \"\"\"\n",
    "    Load a new tag dict to go into the list of dicts for way_tags, node_tags\n",
    "    \"\"\"\n",
    "    new = {}\n",
    "    new['id'] = element.attrib['id']\n",
    "    if \":\" not in secondary.attrib['k']:\n",
    "        new['key'] = secondary.attrib['k']\n",
    "        new['type'] = default_tag_type\n",
    "    else:\n",
    "        post_colon = secondary.attrib['k'].index(\":\") + 1\n",
    "        new['key'] = secondary.attrib['k'][post_colon:]\n",
    "        new['type'] = secondary.attrib['k'][:post_colon - 1]\n",
    "    new['value'] = secondary.attrib['v']\n",
    "    print \"!23123\"\n",
    "    print secondary.attrib['v']\n",
    "    print\"!2312\"\n",
    "    return new\n",
    "\n",
    "\n",
    "def shape_element(element, node_attr_fields=NODE_FIELDS, way_attr_fields=WAY_FIELDS,\n",
    "                  problem_chars=PROBLEMCHARS, default_tag_type='regular'):\n",
    "    \"\"\"Clean and shape node or way XML element to Python dict\"\"\"\n",
    "\n",
    "    node_attribs = {}\n",
    "    way_attribs = {}\n",
    "    way_nodes = []\n",
    "    tags = []  # Handle secondary tags the same way for both node and way elements\n",
    "\n",
    "    if element.tag == 'node':\n",
    "        for attrib, value in element.attrib.iteritems():\n",
    "            if attrib in node_attr_fields:\n",
    "                node_attribs[attrib] = value\n",
    "        \n",
    "        # for elements within the top element\n",
    "        for secondary in element.iter():\n",
    "            if secondary.tag == 'tag':\n",
    "                if problem_chars.match(secondary.attrib['k']) is not None:\n",
    "                    continue\n",
    "                else:\n",
    "                    new = load_new_tag(element, secondary, default_tag_type)\n",
    "                    tags.append(new)\n",
    "        return {'node': node_attribs, 'node_tags': tags}\n",
    "    elif element.tag == 'way':\n",
    "        for attrib, value in element.attrib.iteritems():\n",
    "            if attrib in way_attr_fields:\n",
    "                way_attribs[attrib] = value\n",
    "                \n",
    "        counter = 0\n",
    "        for secondary in element.iter():\n",
    "            if secondary.tag == 'tag':\n",
    "                if problem_chars.match(secondary.attrib['k']) is not None:\n",
    "                    continue\n",
    "                else:\n",
    "                    new = load_new_tag(element, secondary, default_tag_type)\n",
    "                    tags.append(new)\n",
    "            if secondary.tag == 'nd':\n",
    "                newnd = {}\n",
    "                newnd['id'] = element.attrib['id']\n",
    "                newnd['node_id'] = secondary.attrib['ref']\n",
    "                newnd['position'] = counter\n",
    "                counter += 1\n",
    "                way_nodes.append(newnd)\n",
    "        \n",
    "        # print {'way': way_attribs, 'way_nodes': way_nodes, 'way_tags': tags}\n",
    "        return {'way': way_attribs, 'way_nodes': way_nodes, 'way_tags': tags}\n",
    "\n",
    "\n",
    "\n",
    "#               Helper Functions                     #\n",
    "\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\"\"\"\n",
    "\n",
    "    context = ET.iterparse(osm_file, events=('start', 'end'))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "\n",
    "def validate_element(element, validator, schema=SCHEMA):\n",
    "    \"\"\"Raise ValidationError if element does not match schema\"\"\"\n",
    "    if validator.validate(element, schema) is not True:\n",
    "        field, errors = next(validator.errors.iteritems())\n",
    "        message_string = \"\\nElement of type '{0}' has the following errors:\\n{1}\"\n",
    "        error_strings = (\n",
    "            \"{0}: {1}\".format(k, v if isinstance(v, str) else \", \".join(v))\n",
    "            for k, v in errors.iteritems()\n",
    "        )\n",
    "        raise cerberus.ValidationError(\n",
    "            message_string.format(field, \"\\n\".join(error_strings))\n",
    "        )\n",
    "\n",
    "\n",
    "class UnicodeDictWriter(csv.DictWriter, object):\n",
    "    \"\"\"Extend csv.DictWriter to handle Unicode input\"\"\"\n",
    "\n",
    "    def writerow(self, row):\n",
    "        super(UnicodeDictWriter, self).writerow({\n",
    "            k: (v.encode('utf-8') if isinstance(v, unicode) else v) for k, v in row.iteritems()\n",
    "        })\n",
    "\n",
    "    def writerows(self, rows):\n",
    "        for row in rows:\n",
    "            self.writerow(row)\n",
    "\n",
    "\n",
    "#               Main Function                        #\n",
    "\n",
    "def process_map(file_in, validate):\n",
    "    \"\"\"Iteratively process each XML element and write to csv(s)\"\"\"\n",
    "\n",
    "    with codecs.open(NODES_PATH, 'w') as nodes_file, \\\n",
    "         codecs.open(NODE_TAGS_PATH, 'w') as nodes_tags_file, \\\n",
    "         codecs.open(WAYS_PATH, 'w') as ways_file, \\\n",
    "        codecs.open(WAY_NODES_PATH, 'w') as way_nodes_file, \\\n",
    "         codecs.open(WAY_TAGS_PATH, 'w') as way_tags_file:\n",
    "\n",
    "        nodes_writer = UnicodeDictWriter(nodes_file, NODE_FIELDS)\n",
    "        node_tags_writer = UnicodeDictWriter(nodes_tags_file, NODE_TAGS_FIELDS)\n",
    "        ways_writer = UnicodeDictWriter(ways_file, WAY_FIELDS)\n",
    "        way_nodes_writer = UnicodeDictWriter(way_nodes_file, WAY_NODES_FIELDS)\n",
    "        way_tags_writer = UnicodeDictWriter(way_tags_file, WAY_TAGS_FIELDS)\n",
    "\n",
    "        nodes_writer.writeheader()\n",
    "        node_tags_writer.writeheader()\n",
    "        ways_writer.writeheader()\n",
    "        way_nodes_writer.writeheader()\n",
    "        way_tags_writer.writeheader()\n",
    "\n",
    "        validator = cerberus.Validator()\n",
    "\n",
    "        for element in get_element(file_in, tags=('node', 'way')):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                if validate is True:\n",
    "                    validate_element(el, validator)\n",
    "\n",
    "                if element.tag == 'node':\n",
    "                    nodes_writer.writerow(el['node'])\n",
    "                    node_tags_writer.writerows(el['node_tags'])\n",
    "                elif element.tag == 'way':\n",
    "                    ways_writer.writerow(el['way'])\n",
    "                    way_nodes_writer.writerows(el['way_nodes'])\n",
    "                    way_tags_writer.writerows(el['way_tags'])\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Note: Validation is ~ 10X slower. For the project consider using a small\n",
    "    # sample of the map when validating.\n",
    "    process_map(SAMPLE_FILE, validate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some helper functions. additional help!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-13-a79ad7212b60>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-13-a79ad7212b60>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    sqlite> SELECT * FROM nodes WHERE id IN (SELECT DISTINCT(id) FROM nodes_tags_file WHERE key='postcode' AND value='48009')\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sqlite> SELECT * FROM nodes WHERE id IN (SELECT DISTINCT(id) FROM nodes_tags_file WHERE key='postcode' AND value='48009')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overview of the data\n",
    "This section contains basic statistics about the dataset, the SQL queries used to gather them, and some additional ideas about the data in context.\n",
    "File Size\n",
    "Number of Nodes\n",
    "Number of Ways\n",
    "Number of unique users\n",
    "Top 10 contrinuters \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional ideas:\n",
    "List of top 20 Amenities in Stockholm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "process_map() got an unexpected keyword argument 'validate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-6c7d8c10457e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m  \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msqlite3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSAMPLE_FILE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: process_map() got an unexpected keyword argument 'validate'"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import  pandas as pd\n",
    "\n",
    "conn = sqlite3.connect(process_map(SAMPLE_FILE, validate=True))\n",
    "\n",
    "def ll(c):\n",
    "    c = conn.cursor()\n",
    "    c.execute(\"SELECT value, COUNT(*) as num \\\n",
    "            FROM nodes_tags \\\n",
    "           WHERE key='amenity' \\\n",
    "           GROUP BY value \\\n",
    "           ORDER BY num DESC \\\n",
    "           LIMIT 20;\")\n",
    "    \n",
    "    return cursor.fetchall()\n",
    "if __name__ == '__main__':\n",
    "    pprint.pprint(ll(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "DatabaseError",
     "evalue": "Execution failed on sql 'SELECT COUNT(*) FROM con': file is encrypted or is not a database",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-bcf5edaba854>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m  \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msqlite3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nodes_tags.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtracks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_sql_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SELECT COUNT(*) FROM con\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtracks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Farnaz/anaconda/envs/py2/lib/python2.7/site-packages/pandas/io/sql.pyc\u001b[0m in \u001b[0;36mread_sql_query\u001b[0;34m(sql, con, index_col, coerce_float, params, parse_dates, chunksize)\u001b[0m\n\u001b[1;32m    329\u001b[0m     return pandas_sql.read_query(\n\u001b[1;32m    330\u001b[0m         \u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoerce_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m         parse_dates=parse_dates, chunksize=chunksize)\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Farnaz/anaconda/envs/py2/lib/python2.7/site-packages/pandas/io/sql.pyc\u001b[0m in \u001b[0;36mread_query\u001b[0;34m(self, sql, index_col, coerce_float, params, parse_dates, chunksize)\u001b[0m\n\u001b[1;32m   1434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1436\u001b[0;31m         \u001b[0mcursor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1437\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcol_desc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol_desc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Farnaz/anaconda/envs/py2/lib/python2.7/site-packages/pandas/io/sql.pyc\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1411\u001b[0m             ex = DatabaseError(\n\u001b[1;32m   1412\u001b[0m                 \"Execution failed on sql '%s': %s\" % (args[0], exc))\n\u001b[0;32m-> 1413\u001b[0;31m             \u001b[0mraise_with_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1415\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Farnaz/anaconda/envs/py2/lib/python2.7/site-packages/pandas/io/sql.pyc\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1399\u001b[0m                 \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1400\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1401\u001b[0;31m                 \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1402\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcur\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1403\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDatabaseError\u001b[0m: Execution failed on sql 'SELECT COUNT(*) FROM con': file is encrypted or is not a database"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import  pandas as pd\n",
    "con = sqlite3.connect(\"nodes_tags.csv\")\n",
    "tracks = pd.read_sql_query(\"SELECT COUNT(*) FROM con\", con=con)\n",
    "tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sqlite> SELECT nodes_tags.value, COUNT(*) as num\n",
    "FROM nodes_tags \n",
    "    JOIN (SELECT DISTINCT(id) FROM nodes_tags WHERE value='restaurant') i \n",
    "    ON nodes_tags.id=i.id\n",
    "WHERE nodes_tags.key=\"cuisine\"\n",
    "GROUP BY nodes_tags.value\n",
    "ORDER BY num DESC;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion\n",
    "From the process of auditing we can see the dataset is fairly well-cleaned even though there are some minor error such as inconsistent postal codes. Since there are thousands of contributing users, so it is inevitable to have many human input error. My thought is: is it possible to create a monitor system to check everybody’s contribution regularly. In addition, because OpenStreetMaps is an open source project, there’re still a lot of areas map outdated such as my fav city, Stockholm. So I hope OpenStreetMaps can obtain these data from other open data sources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional Suggestion and Ideas\n",
    "\n",
    "Control typo errors\n",
    "\n",
    "We can build parser which parse every word input by the users.\n",
    "We can make some rules or patterns to input data which users follow everytime to input their data. This will also restrict users input in their native language.\n",
    "We can develope script or bot to clean the data regularly or certain period."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
